Metadata-Version: 2.4
Name: retrofit
Version: 0.1.7
Summary: AutoML, Forecasting, NLP, Image Classification, Feature Engineering, Model Evaluation, Model Interpretation, Fast Processing.
Home-page: https://github.com/AdrianAntico/retrofit
Author: ['Adrian Antico', 'Sean Benner']
Author-email: adrianantico@gmail.com
License: MIT
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: polars
Requires-Dist: pandas
Requires-Dist: numpy
Requires-Dist: scipy
Requires-Dist: statsmodels
Requires-Dist: catboost
Requires-Dist: xgboost
Requires-Dist: lightgbm
Requires-Dist: torch
Requires-Dist: QuickEcharts
Requires-Dist: PolarsFE
Requires-Dist: pyarrow
Requires-Dist: scikit-learn
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: license
Dynamic: license-file
Dynamic: requires-dist
Dynamic: summary

![Version: 0.1.7](https://img.shields.io/static/v1?label=Version&message=0.1.7&color=blue&?style=plastic)
![Python](https://img.shields.io/badge/Python-3.6%20%7C%203.7%20%7C%203.8%20%7C%203.9-blue)
![Build: Passing](https://img.shields.io/static/v1?label=Build&message=passing&color=brightgreen)
[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://GitHub.com/Naereen/StrapDown.js/graphs/commit-activity)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=default)](http://makeapullrequest.com)
[![GitHub Stars](https://img.shields.io/github/stars/AdrianAntico/RetroFit.svg?style=social)](https://github.com/AdrianAntico/retrofit)

<img src='https://raw.githubusercontent.com/AdrianAntico/RetroFit/main/images/PackageLogo.PNG' align='center' width='1000' />

Table of Contents
- [**Quick Note**](#quick-note)
- [**Installation**](#installation)
- [**Machine Learning Note**](#machine-learning-note)

Documentation + Code Examples
- [**Machine Learning**](#machine-learning)


## **Quick Note**
This package is currently in its beginning stages. I'll be working off a blueprint from my R package AutoQuant so there should be minimal breakages upon new releases, only non-breaking enhancements and additions. 

## **Installation**
```python
# Most up-to-date
pip install git+https://github.com/AdrianAntico/RetroFit.git#egg=retrofit

# From pypi
pip install retrofit==0.1.7

# Check out R package AutoQuant
https://github.com/AdrianAntico/AutoQuant
```


## **Machine Learning Note**

> Machine Learning Training: the goal here is enable the data scientist or machine learning engineer to effortlessly build any number of models with full optionality to tweak all available underlying parameters offered by the various algorithms. The underlying data can come from datatable or polars which means you'll be able to model with bigger data than if you were utilizing pandas. All models come with the ability to generate comprehensive evaluation metrics, evaluation plots, importances, and feature insights. Scoring should be seamless, from regenerating features for scoring to the actual scoring. The RetroFit class makes this super easy, fast, with minimal memory utilization.



<img src='https://raw.githubusercontent.com/AdrianAntico/RetroFit/main/images/Documentation.PNG' align='center' width='1000' />


### **RetroFit Class**
<p>

<details><summary>CatBoost Examples</summary>
<p>

<details><summary>Regression Training</summary>
<p>

```python
####################################
# CatBoost Regression
####################################

# Setup Environment
import pkg_resources
import timeit
import datatable as dt
import retrofit
from retrofit import DatatableFE as dtfe
from retrofit import MachineLearning as ml

# Load some data
FilePath = pkg_resources.resource_filename('retrofit', 'datasets/RegressionData.csv') 
data = dt.fread(FilePath)

# Instantiate Feature Engineering Class
FE = dtfe.FE()

# Create some lags
data = FE.FE0_AutoLags(
    data,
    LagColumnNames=['Independent_Variable1', 'Independent_Variable2'],
    DateColumnName='DateTime',
    ByVariables='Factor_1',
    LagPeriods=[1,2],
    ImputeValue=-1,
    Sort=True,
    use_saved_args=False)

# Create some rolling stats
data = FE.FE0_AutoRollStats(
    data,
    RollColumnNames=['Independent_Variable1','Independent_Variable2'],
    DateColumnName='DateTime',
    ByVariables='Factor_1',
    MovingAvg_Periods=[1,2],
    MovingSD_Periods=[2,3],
    MovingMin_Periods=[1,2],
    MovingMax_Periods=[1,2],
    ImputeValue=-1,
    Sort=True,
    use_saved_args=False)

# Create some diffs
data = FE.FE0_AutoDiff(
    data,
    DateColumnName='DateTime',
    ByVariables=['Factor_1','Factor_2','Factor_3'],
    DiffNumericVariables='Independent_Variable1',
    DiffDateVariables=None,
    DiffGroupVariables=None,
    NLag1=0,
    NLag2=1,
    Sort=True,
    use_saved_args=False)

# Create Calendar Vars
data = FE.FE1_AutoCalendarVariables(
    data,
    DateColumnNames='DateTime',
    CalendarVariables=['wday','month','quarter'],
    use_saved_args=False)

# Type conversions for modeling
data = FE.FE2_ColTypeConversions(
    data,
    Int2Float=True,
    Bool2Float=True,
    RemoveDateCols=True,
    RemoveStrCols=False,
    SkipCols=None,
    use_saved_args=False)

# Drop Text Cols (no word2vec yet)
data = data[:, [z for z in data.names if z not in ['Comment']]]

# Create partitioned data sets
DataFrames = FE.FE2_AutoDataPartition(
    data, 
    DateColumnName = None, 
    PartitionType = 'random', 
    Ratios = [0.7,0.2,0.1], 
    ByVariables = None, 
    Sort = False,
    use_saved_args = False)

# Prepare modeling data sets
ModelData = ml.ML0_GetModelData(
    Processing = 'catboost',
    TrainData = DataFrames['TrainData'],
    ValidationData = DataFrames['ValidationData'],
    TestData = DataFrames['TestData'],
    ArgsList = None,
    TargetColumnName = 'Adrian',
    NumericColumnNames = [z for z in list(data.names) if z not in ['Factor_1','Factor_2','Factor_3','Adrian']],
    CategoricalColumnNames = ['Factor_1', 'Factor_2', 'Factor_3'],
    TextColumnNames = None,
    WeightColumnName = None,
    Threads = -1,
    InputFrame = 'datatable')

# Get args list for algorithm and target type
ModelArgs = ml.ML0_Parameters(
    Algorithms = 'CatBoost', 
    TargetType = 'Regression', 
    TrainMethod = 'Train')

# Update iterations to run quickly
ModelArgs.get('CatBoost').get('AlgoArgs')['iterations'] = 50

# Initialize RetroFit
x = ml.RetroFit(ModelArgs, ModelData, DataFrames)

# Train Model
x.ML1_Single_Train(Algorithm = 'CatBoost')

# Score data
x.ML1_Single_Score(
    DataName = x.DataSetsNames[2], 
    ModelName = x.ModelListNames[0],
    Algorithm = 'CatBoost',
    NewData = None)

# Evaluate scored data
metrics = x.ML1_Single_Evaluate(
    FitName=x.FitListNames[0],
    TargetType=x.ModelArgs.get('CatBoost')['TargetType'],
    ScoredDataName=x.DataSetsNames[-1],
    ByVariables=None,
    CostDict=None)

# Metrics
metrics.keys()

# Scoring data names
x.DataSetsNames

# Scoring data
x.DataSets.get('Scored_test_data_CatBoost_1')

# Check ModelArgs Dict
x.PrintAlgoArgs(Algo = 'CatBoost')

# List of model names
x.ModelListNames

# List of model fitted names
x.FitListNames
```

</p>
</details>


<details><summary>Classification Training</summary>
<p>

```python
####################################
# CatBoost Classification
####################################

# Setup Environment
import pkg_resources
import timeit
import datatable as dt
import retrofit
from retrofit import DatatableFE as dtfe
from retrofit import MachineLearning as ml

# Load some data
FilePath = pkg_resources.resource_filename('retrofit', 'datasets/ClassificationData.csv') 
data = dt.fread(FilePath)

# Instantiate Feature Engineering Class
FE = dtfe.FE()

# Create some lags
data = FE.FE0_AutoLags(
    data,
    LagColumnNames=['Independent_Variable1', 'Independent_Variable2'],
    DateColumnName='DateTime',
    ByVariables='Factor_1',
    LagPeriods=[1,2],
    ImputeValue=-1,
    Sort=True,
    use_saved_args=False)

# Create some rolling stats
data = FE.FE0_AutoRollStats(
    data,
    RollColumnNames=['Independent_Variable1','Independent_Variable2'],
    DateColumnName='DateTime',
    ByVariables='Factor_1',
    MovingAvg_Periods=[1,2],
    MovingSD_Periods=[2,3],
    MovingMin_Periods=[1,2],
    MovingMax_Periods=[1,2],
    ImputeValue=-1,
    Sort=True,
    use_saved_args=False)

# Create some diffs
data = FE.FE0_AutoDiff(
    data,
    DateColumnName='DateTime',
    ByVariables=['Factor_1','Factor_2','Factor_3'],
    DiffNumericVariables='Independent_Variable1',
    DiffDateVariables=None,
    DiffGroupVariables=None,
    NLag1=0,
    NLag2=1,
    Sort=True,
    use_saved_args=False)

# Create Calendar Vars
data = FE.FE1_AutoCalendarVariables(
    data,
    DateColumnNames='DateTime',
    CalendarVariables=['wday','month','quarter'],
    use_saved_args=False)

# Type conversions for modeling
data = FE.FE2_ColTypeConversions(
    data,
    Int2Float=True,
    Bool2Float=True,
    RemoveDateCols=True,
    RemoveStrCols=False,
    SkipCols=None,
    use_saved_args=False)

# Drop Text Cols (no word2vec yet)
data = data[:, [z for z in data.names if z not in ['Comment']]]

# Create partitioned data sets
DataFrames = FE.FE2_AutoDataPartition(
    data, 
    DateColumnName = None, 
    PartitionType = 'random', 
    Ratios = [0.7,0.2,0.1], 
    ByVariables = None, 
    Sort = False,
    use_saved_args = False)

# Prepare modeling data sets
ModelData = ml.ML0_GetModelData(
    Processing = 'catboost',
    TrainData = DataFrames['TrainData'],
    ValidationData = DataFrames['ValidationData'],
    TestData = DataFrames['TestData'],
    ArgsList = None,
    TargetColumnName = 'Adrian',
    NumericColumnNames = [z for z in list(data.names) if z not in ['Factor_1','Factor_2','Factor_3','Adrian']],
    CategoricalColumnNames = ['Factor_1', 'Factor_2', 'Factor_3'],
    TextColumnNames = None,
    WeightColumnName = None,
    Threads = -1,
    InputFrame = 'datatable')

# Get args list for algorithm and target type
ModelArgs = ml.ML0_Parameters(
    Algorithms = 'CatBoost', 
    TargetType = 'Classification', 
    TrainMethod = 'Train')

# Update iterations to run quickly
ModelArgs.get('CatBoost').get('AlgoArgs')['iterations'] = 50

# Initialize RetroFit
x = ml.RetroFit(ModelArgs, ModelData, DataFrames)

# Train Model
x.ML1_Single_Train(Algorithm = 'CatBoost')

# Score data
x.ML1_Single_Score(
    DataName = x.DataSetsNames[2], 
    ModelName = x.ModelListNames[0],
    Algorithm = 'CatBoost',
    NewData = None)

# Evaluate scored data
metrics = x.ML1_Single_Evaluate(
    FitName=x.FitListNames[0],
    TargetType=x.ModelArgs.get('CatBoost')['TargetType'],
    ScoredDataName=x.DataSetsNames[-1],
    ByVariables=None,
    CostDict=dict(tpcost=0, fpcost=1, fncost=1, tncost=0))

# Metrics
metrics.keys()

# Scoring data names
x.DataSetsNames

# Scoring data
x.DataSets.get('Scored_test_data_CatBoost_1')

# Check ModelArgs Dict
x.PrintAlgoArgs(Algo = 'CatBoost')

# List of model names
x.ModelListNames

# List of model fitted names
x.FitListNames
```

</p>
</details>


<details><summary>MultiClass Training</summary>
<p>

```python
####################################
# CatBoost MultiClass
####################################

# Setup Environment
import pkg_resources
import timeit
import datatable as dt
import retrofit
from retrofit import DatatableFE as dtfe
from retrofit import MachineLearning as ml

# Load some data
FilePath = pkg_resources.resource_filename('retrofit', 'datasets/MultiClassData.csv') 
data = dt.fread(FilePath)

# Instantiate Feature Engineering Class
FE = dtfe.FE()

# Create Calendar Vars
data = FE.FE1_AutoCalendarVariables(
    data,
    DateColumnNames='DateTime',
    CalendarVariables=['wday','month','quarter'],
    use_saved_args=False)

# Type conversions for modeling
data = FE.FE2_ColTypeConversions(
    data,
    Int2Float=True,
    Bool2Float=True,
    RemoveDateCols=True,
    RemoveStrCols=False,
    SkipCols=None,
    use_saved_args=False)

# Drop Text Cols (no word2vec yet)
data = data[:, [z for z in data.names if z not in ['Comment']]]

# Create partitioned data sets
DataFrames = FE.FE2_AutoDataPartition(
    data, 
    DateColumnName = None, 
    PartitionType = 'random', 
    Ratios = [0.7,0.2,0.1], 
    ByVariables = None, 
    Sort = False,
    use_saved_args = False)

# Features for modeling
Features = [z for z in list(data.names) if z not in ['Factor_2','Factor_3','Adrian']]

# Prepare modeling data sets
ModelData = ml.ML0_GetModelData(
    Processing = 'catboost',
    TrainData = DataFrames['TrainData'],
    ValidationData = DataFrames['ValidationData'],
    TestData = DataFrames['TestData'],
    ArgsList = None,
    TargetColumnName = 'Adrian',
    NumericColumnNames = Features,
    CategoricalColumnNames = ['Factor_2', 'Factor_3'],
    TextColumnNames = None,
    WeightColumnName = None,
    Threads = -1,
    InputFrame = 'datatable')

# Get args list for algorithm and target type
ModelArgs = ml.ML0_Parameters(
    Algorithms = 'CatBoost',
    TargetType = 'MultiClass',
    TrainMethod = 'Train')

# Update iterations to run quickly
ModelArgs.get('CatBoost').get('AlgoArgs')['iterations'] = 50

# Initialize RetroFit
x = ml.RetroFit(ModelArgs, ModelData, DataFrames)

# Train Model
x.ML1_Single_Train(Algorithm = 'CatBoost')

# Score data
x.ML1_Single_Score(
    DataName = x.DataSetsNames[2], 
    ModelName = x.ModelListNames[0],
    Algorithm = 'CatBoost',
    NewData = None)

# Evaluate scored data
metrics = x.ML1_Single_Evaluate(
    FitName=x.FitListNames[0],
    TargetType=x.ModelArgs.get('CatBoost')['TargetType'],
    ScoredDataName=x.DataSetsNames[-1],
    ByVariables=None,
    CostDict=dict(tpcost=0, fpcost=1, fncost=1, tncost=0))

# Metrics
metrics.keys()

# Scoring data names
x.DataSetsNames

# Scoring data
x.DataSets.get('Scored_test_data_CatBoost_1')

# Check ModelArgs Dict
x.PrintAlgoArgs(Algo = 'CatBoost')

# List of model names
x.ModelListNames

# List of model fitted names
x.FitListNames
```

</p>
</details>


</p>
</details>



<details><summary>XGBoost Examples</summary>
<p>


<details><summary>Regression Training</summary>
<p>


```python
####################################
# XGBoost Regression
####################################

# Setup Environment
import pkg_resources
import timeit
import datatable as dt
import retrofit
from retrofit import DatatableFE as dtfe
from retrofit import MachineLearning as ml

# Load some data
FilePath = pkg_resources.resource_filename('retrofit', 'datasets/RegressionData.csv') 
data = dt.fread(FilePath)

# Instantiate Feature Engineering Class
FE = dtfe.FE()

# Create some lags
data = FE.FE0_AutoLags(
    data,
    LagColumnNames=['Independent_Variable1', 'Independent_Variable2'],
    DateColumnName='DateTime',
    ByVariables='Factor_1',
    LagPeriods=[1,2],
    ImputeValue=-1,
    Sort=True,
    use_saved_args=False)

# Create some rolling stats
data = FE.FE0_AutoRollStats(
    data,
    RollColumnNames=['Independent_Variable1','Independent_Variable2'],
    DateColumnName='DateTime',
    ByVariables='Factor_1',
    MovingAvg_Periods=[1,2],
    MovingSD_Periods=[2,3],
    MovingMin_Periods=[1,2],
    MovingMax_Periods=[1,2],
    ImputeValue=-1,
    Sort=True,
    use_saved_args=False)

# Create some diffs
data = FE.FE0_AutoDiff(
    data,
    DateColumnName='DateTime',
    ByVariables=['Factor_1','Factor_2','Factor_3'],
    DiffNumericVariables='Independent_Variable1',
    DiffDateVariables=None,
    DiffGroupVariables=None,
    NLag1=0,
    NLag2=1,
    Sort=True,
    use_saved_args=False)

# Dummify
data = FE.FE1_DummyVariables(
    data = data, 
    CategoricalColumnNames = ['Factor_1','Factor_2','Factor_3'],
    use_saved_args=False)
data = data[:, [name not in ['Factor_1','Factor_2','Factor_3'] for name in data.names]]

# Create Calendar Vars
data = FE.FE1_AutoCalendarVariables(
    data,
    DateColumnNames='DateTime',
    CalendarVariables=['wday','month','quarter'],
    use_saved_args=False)

# Type conversions for modeling
data = FE.FE2_ColTypeConversions(
    data,
    Int2Float=True,
    Bool2Float=True,
    RemoveDateCols=True,
    RemoveStrCols=False,
    SkipCols=None,
    use_saved_args=False)

# Drop Text Cols (no word2vec yet)
data = data[:, [z for z in data.names if z not in ['Comment']]]

# Create partitioned data sets
DataFrames = FE.FE2_AutoDataPartition(
    data, 
    DateColumnName = None, 
    PartitionType = 'random', 
    Ratios = [0.7,0.2,0.1], 
    ByVariables = None, 
    Sort = False,
    use_saved_args = False)

# Features
Features = [z for z in list(data.names) if not z in ['Adrian','DateTime','Comment','Weights']]

# Prepare modeling data sets
ModelData = ml.ML0_GetModelData(
    Processing = 'xgboost',
    TrainData = DataFrames['TrainData'],
    ValidationData = DataFrames['ValidationData'],
    TestData = DataFrames['TestData'],
    ArgsList = None,
    TargetColumnName = 'Adrian',
    NumericColumnNames = Features,
    CategoricalColumnNames = None,
    TextColumnNames = None,
    WeightColumnName = None,
    Threads = -1,
    InputFrame = 'datatable')

# Get args list for algorithm and target type
ModelArgs = ml.ML0_Parameters(
    Algorithms = 'XGBoost', 
    TargetType = "Regression", 
    TrainMethod = "Train")

# Update iterations to run quickly
ModelArgs['XGBoost']['AlgoArgs']['num_boost_round'] = 50

# Initialize RetroFit
x = ml.RetroFit(ModelArgs, ModelData, DataFrames)

# Train Model
x.ML1_Single_Train(Algorithm = 'XGBoost')

# Score data
x.ML1_Single_Score(
    DataName = x.DataSetsNames[2],
    ModelName = x.ModelListNames[0],
    Algorithm = 'XGBoost',
    NewData = None)

# Evaluate scored data
metrics = x.ML1_Single_Evaluate(
    FitName=x.FitListNames[0],
    TargetType=x.ModelArgs.get('XGBoost')['TargetType'],
    ScoredDataName=x.DataSetsNames[-1],
    ByVariables=None,
    CostDict=None)

# Metrics
metrics.keys()

# Scoring data names
x.DataSetsNames

# Scoring data
x.DataSets.get('Scored_test_data_XGBoost_1')

# Check ModelArgs Dict
x.PrintAlgoArgs(Algo = 'XGBoost')

# List of model names
x.ModelListNames

# List of model fitted names
x.FitListNames
```

</p>
</details>


<details><summary>Classification Training</summary>
<p>

```python
####################################
# XGBoost Classification
####################################

# Setup Environment
import pkg_resources
import timeit
import datatable as dt
import retrofit
from retrofit import DatatableFE as dtfe
from retrofit import MachineLearning as ml

# Load some data
FilePath = pkg_resources.resource_filename('retrofit', 'datasets/ClassificationData.csv') 
data = dt.fread(FilePath)

# Instantiate Feature Engineering Class
FE = dtfe.FE()

# Create some lags
data = FE.FE0_AutoLags(
    data,
    LagColumnNames=['Independent_Variable1', 'Independent_Variable2'],
    DateColumnName='DateTime',
    ByVariables='Factor_1',
    LagPeriods=[1,2],
    ImputeValue=-1,
    Sort=True,
    use_saved_args=False)

# Create some rolling stats
data = FE.FE0_AutoRollStats(
    data,
    RollColumnNames=['Independent_Variable1','Independent_Variable2'],
    DateColumnName='DateTime',
    ByVariables='Factor_1',
    MovingAvg_Periods=[1,2],
    MovingSD_Periods=[2,3],
    MovingMin_Periods=[1,2],
    MovingMax_Periods=[1,2],
    ImputeValue=-1,
    Sort=True,
    use_saved_args=False)

# Create some diffs
data = FE.FE0_AutoDiff(
    data,
    DateColumnName='DateTime',
    ByVariables=['Factor_1','Factor_2','Factor_3'],
    DiffNumericVariables='Independent_Variable1',
    DiffDateVariables=None,
    DiffGroupVariables=None,
    NLag1=0,
    NLag2=1,
    Sort=True,
    use_saved_args=False)

# Dummify
data = FE.FE1_DummyVariables(
    data = data, 
    CategoricalColumnNames = ['Factor_1','Factor_2','Factor_3'],
    use_saved_args=False)
data = data[:, [name not in ['Factor_1','Factor_2','Factor_3'] for name in data.names]]

# Create Calendar Vars
data = FE.FE1_AutoCalendarVariables(
    data,
    DateColumnNames='DateTime',
    CalendarVariables=['wday','month','quarter'],
    use_saved_args=False)

# Type conversions for modeling
data = FE.FE2_ColTypeConversions(
    data,
    Int2Float=True,
    Bool2Float=True,
    RemoveDateCols=True,
    RemoveStrCols=False,
    SkipCols=None,
    use_saved_args=False)

# Drop Text Cols (no word2vec yet)
data = data[:, [z for z in data.names if z not in ['Comment']]]

# Create partitioned data sets
DataFrames = FE.FE2_AutoDataPartition(
    data, 
    DateColumnName = None, 
    PartitionType = 'random', 
    Ratios = [0.7,0.2,0.1], 
    ByVariables = None, 
    Sort = False,
    use_saved_args = False)

# Features
Features = [z for z in list(data.names) if not z in ['Adrian','DateTime','Comment','Weights']]

# Prepare modeling data sets
ModelData = ml.ML0_GetModelData(
    Processing = 'xgboost',
    TrainData = DataFrames['TrainData'],
    ValidationData = DataFrames['ValidationData'],
    TestData = DataFrames['TestData'],
    ArgsList = None,
    TargetColumnName = 'Adrian',
    NumericColumnNames = Features,
    CategoricalColumnNames = None,
    TextColumnNames = None,
    WeightColumnName = None,
    Threads = -1,
    InputFrame = 'datatable')

# Get args list for algorithm and target type
ModelArgs = ml.ML0_Parameters(
    Algorithms = 'XGBoost', 
    TargetType = 'Classification', 
    TrainMethod = 'Train')

# Update iterations to run quickly
ModelArgs.get('XGBoost').get('AlgoArgs')['num_boost_round'] = 50

# Initialize RetroFit
x = ml.RetroFit(ModelArgs, ModelData, DataFrames)

# Train Model
x.ML1_Single_Train(Algorithm = 'XGBoost')

# Score data
x.ML1_Single_Score(
    DataName = x.DataSetsNames[2],
    ModelName = x.ModelListNames[0],
    Algorithm = 'XGBoost',
    NewData = None)

# Evaluate scored data
metrics = x.ML1_Single_Evaluate(
    FitName=x.FitListNames[0],
    TargetType=x.ModelArgs.get('XGBoost')['TargetType'],
    ScoredDataName=x.DataSetsNames[-1],
    ByVariables=None,
    CostDict=dict(tpcost=0, fpcost=1, fncost=1, tncost=0))

# Metrics
metrics.keys()

# Scoring data names
x.DataSetsNames

# Scoring data
x.DataSets.get('Scored_test_data_XGBoost_1')

# Check ModelArgs Dict
x.PrintAlgoArgs(Algo = 'XGBoost')

# List of model names
x.ModelListNames

# List of model fitted names
x.FitListNames
```

</p>
</details>


<details><summary>MultiClass Training</summary>
<p>

```python
####################################
# XGBoost MultiClass
####################################

# Setup Environment
import pkg_resources
import timeit
import datatable as dt
import retrofit
from retrofit import DatatableFE as dtfe
from retrofit import MachineLearning as ml

# Load some data
FilePath = pkg_resources.resource_filename('retrofit', 'datasets/MultiClassData.csv') 
data = dt.fread(FilePath)

# Instantiate Feature Engineering Class
FE = dtfe.FE()

# Dummify
data = FE.FE1_DummyVariables(
    data = data, 
    CategoricalColumnNames = ['Factor_2','Factor_3'],
    use_saved_args=False)
data = data[:, [name not in ['Factor_2','Factor_3'] for name in data.names]]

# Create Calendar Vars
data = FE.FE1_AutoCalendarVariables(
    data,
    DateColumnNames='DateTime',
    CalendarVariables=['wday','month','quarter'],
    use_saved_args=False)

# Type conversions for modeling
data = FE.FE2_ColTypeConversions(
    data,
    Int2Float=True,
    Bool2Float=True,
    RemoveDateCols=True,
    RemoveStrCols=False,
    SkipCols=None,
    use_saved_args=False)

# Drop Text Cols (no word2vec yet)
data = data[:, [z for z in data.names if z not in ['Comment']]]

# Create partitioned data sets
DataFrames = FE.FE2_AutoDataPartition(
    data, 
    DateColumnName = None, 
    PartitionType = 'random', 
    Ratios = [0.7,0.2,0.1], 
    ByVariables = None, 
    Sort = False,
    use_saved_args = False)

# Features
Features = [z for z in list(data.names) if not z in ['Adrian','DateTime','Comment','Weights']]

# Prepare modeling data sets
ModelData = ml.ML0_GetModelData(
    Processing = 'xgboost',
    TrainData = DataFrames['TrainData'],
    ValidationData = DataFrames['ValidationData'],
    TestData = DataFrames['TestData'],
    ArgsList = None,
    TargetColumnName = 'Adrian',
    NumericColumnNames = Features,
    CategoricalColumnNames = None,
    TextColumnNames = None,
    WeightColumnName = None,
    Threads = -1,
    InputFrame = 'datatable')

# Get args list for algorithm and target type
ModelArgs = ml.ML0_Parameters(
    Algorithms = 'XGBoost',
    TargetType = 'MultiClass',
    TrainMethod = 'Train')

# Update iterations to run quickly
ModelArgs.get('XGBoost').get('AlgoArgs')['num_boost_round'] = 50

# Initialize RetroFit
x = ml.RetroFit(ModelArgs, ModelData, DataFrames)

# Train Model
x.ML1_Single_Train(Algorithm = 'XGBoost')

# Score data
x.ML1_Single_Score(
    DataName = x.DataSetsNames[2],
    ModelName = x.ModelListNames[0],
    Algorithm = 'XGBoost',
    NewData = None)

# Scoring data names
x.DataSetsNames

# Scoring data
x.DataSets.get('Scored_test_data_XGBoost_1')

# Check ModelArgs Dict
x.PrintAlgoArgs(Algo = 'XGBoost')

# List of model names
x.ModelListNames

# List of model fitted names
x.FitListNames
```

</p>
</details>

</p>
</details>


<details><summary>LightGBM Examples</summary>
<p>


<details><summary>Regression Training</summary>
<p>

```python
####################################
# LightGBM Regression
####################################

# Setup Environment
import pkg_resources
import timeit
import datatable as dt
import retrofit
from retrofit import DatatableFE as dtfe
from retrofit import MachineLearning as ml

# Load some data
FilePath = pkg_resources.resource_filename('retrofit', 'datasets/RegressionData.csv') 
data = dt.fread(FilePath)

# Instantiate Feature Engineering Class
FE = dtfe.FE()

# Create some lags
data = FE.FE0_AutoLags(
    data,
    LagColumnNames=['Independent_Variable1', 'Independent_Variable2'],
    DateColumnName='DateTime',
    ByVariables='Factor_1',
    LagPeriods=[1,2],
    ImputeValue=-1,
    Sort=True,
    use_saved_args=False)

# Create some rolling stats
data = FE.FE0_AutoRollStats(
    data,
    RollColumnNames=['Independent_Variable1','Independent_Variable2'],
    DateColumnName='DateTime',
    ByVariables='Factor_1',
    MovingAvg_Periods=[1,2],
    MovingSD_Periods=[2,3],
    MovingMin_Periods=[1,2],
    MovingMax_Periods=[1,2],
    ImputeValue=-1,
    Sort=True,
    use_saved_args=False)

# Create some diffs
data = FE.FE0_AutoDiff(
    data,
    DateColumnName='DateTime',
    ByVariables=['Factor_1','Factor_2','Factor_3'],
    DiffNumericVariables='Independent_Variable1',
    DiffDateVariables=None,
    DiffGroupVariables=None,
    NLag1=0,
    NLag2=1,
    Sort=True,
    use_saved_args=False)

# Dummify
data = FE.FE1_DummyVariables(
    data = data, 
    CategoricalColumnNames = ['Factor_1','Factor_2','Factor_3'],
    use_saved_args=False)
data = data[:, [name not in ['Factor_1','Factor_2','Factor_3'] for name in data.names]]

# Create Calendar Vars
data = FE.FE1_AutoCalendarVariables(
    data,
    DateColumnNames='DateTime',
    CalendarVariables=['wday','month','quarter'],
    use_saved_args=False)

# Type conversions for modeling
data = FE.FE2_ColTypeConversions(
    data,
    Int2Float=True,
    Bool2Float=True,
    RemoveDateCols=True,
    RemoveStrCols=False,
    SkipCols=None,
    use_saved_args=False)

# Drop Text Cols (no word2vec yet)
data = data[:, [z for z in data.names if z not in ['Comment']]]

# Create partitioned data sets
DataFrames = FE.FE2_AutoDataPartition(
    data, 
    DateColumnName = None, 
    PartitionType = 'random', 
    Ratios = [0.7,0.2,0.1], 
    ByVariables = None, 
    Sort = False,
    use_saved_args = False)

# Features
Features = [z for z in list(data.names) if not z in ['Adrian','DateTime','Comment','Weights']]

# Prepare modeling data sets
ModelData = ml.ML0_GetModelData(
    Processing = 'lightgbm',
    TrainData = DataFrames['TrainData'],
    ValidationData = DataFrames['ValidationData'],
    TestData = DataFrames['TestData'],
    ArgsList = None,
    TargetColumnName = 'Adrian',
    NumericColumnNames = Features,
    CategoricalColumnNames = None,
    TextColumnNames = None,
    WeightColumnName = None,
    Threads = -1,
    InputFrame = 'datatable')

# Get args list for algorithm and target type
ModelArgs = ml.ML0_Parameters(
    Algorithms = 'LightGBM', 
    TargetType = 'Regression', 
    TrainMethod = 'Train')

# Update iterations to run quickly
ModelArgs.get('LightGBM').get('AlgoArgs')['num_iterations'] = 50

# Initialize RetroFit
x = ml.RetroFit(ModelArgs, ModelData, DataFrames)

# Train Model
x.ML1_Single_Train(Algorithm = 'LightGBM')

# Score data
x.ML1_Single_Score(
    DataName = x.DataSetsNames[2],
    ModelName = x.ModelListNames[0],
    Algorithm = 'LightGBM')

# Scoring data names
x.DataSetsNames

# Scoring data
x.DataSets.get('Scored_test_data_LightGBM_1')

# Check ModelArgs Dict
x.PrintAlgoArgs(Algo = 'LightGBM')

# List of model names
x.ModelListNames

# List of model fitted names
x.FitListNames
```

</p>
</details>


<details><summary>Classification Training</summary>
<p>

```python
####################################
# LightGBM Classification
####################################

# Setup Environment
import pkg_resources
import timeit
import datatable as dt
import retrofit
from retrofit import DatatableFE as dtfe
from retrofit import MachineLearning as ml

# Load some data
FilePath = pkg_resources.resource_filename('retrofit', 'datasets/ClassificationData.csv') 
data = dt.fread(FilePath)

# Instantiate Feature Engineering Class
FE = dtfe.FE()

# Create some lags
data = FE.FE0_AutoLags(
    data,
    LagColumnNames=['Independent_Variable1', 'Independent_Variable2'],
    DateColumnName='DateTime',
    ByVariables='Factor_1',
    LagPeriods=[1,2],
    ImputeValue=-1,
    Sort=True,
    use_saved_args=False)

# Create some rolling stats
data = FE.FE0_AutoRollStats(
    data,
    RollColumnNames=['Independent_Variable1','Independent_Variable2'],
    DateColumnName='DateTime',
    ByVariables='Factor_1',
    MovingAvg_Periods=[1,2],
    MovingSD_Periods=[2,3],
    MovingMin_Periods=[1,2],
    MovingMax_Periods=[1,2],
    ImputeValue=-1,
    Sort=True,
    use_saved_args=False)

# Create some diffs
data = FE.FE0_AutoDiff(
    data,
    DateColumnName='DateTime',
    ByVariables=['Factor_1','Factor_2','Factor_3'],
    DiffNumericVariables='Independent_Variable1',
    DiffDateVariables=None,
    DiffGroupVariables=None,
    NLag1=0,
    NLag2=1,
    Sort=True,
    use_saved_args=False)

# Dummify
data = FE.FE1_DummyVariables(
    data = data, 
    CategoricalColumnNames = ['Factor_1','Factor_2','Factor_3'],
    use_saved_args=False)
data = data[:, [name not in ['Factor_1','Factor_2','Factor_3'] for name in data.names]]

# Create Calendar Vars
data = FE.FE1_AutoCalendarVariables(
    data,
    DateColumnNames='DateTime',
    CalendarVariables=['wday','month','quarter'],
    use_saved_args=False)

# Type conversions for modeling
data = FE.FE2_ColTypeConversions(
    data,
    Int2Float=True,
    Bool2Float=True,
    RemoveDateCols=True,
    RemoveStrCols=False,
    SkipCols=None,
    use_saved_args=False)

# Drop Text Cols (no word2vec yet)
data = data[:, [z for z in data.names if z not in ['Comment']]]

# Create partitioned data sets
DataFrames = FE.FE2_AutoDataPartition(
    data, 
    DateColumnName = None, 
    PartitionType = 'random', 
    Ratios = [0.7,0.2,0.1], 
    ByVariables = None, 
    Sort = False,
    use_saved_args = False)

# Features
Features = [z for z in list(data.names) if not z in ['Adrian','DateTime','Comment','Weights']]

# Prepare modeling data sets
ModelData = ml.ML0_GetModelData(
    Processing = 'lightgbm',
    TrainData = DataFrames['TrainData'],
    ValidationData = DataFrames['ValidationData'],
    TestData = DataFrames['TestData'],
    ArgsList = None,
    TargetColumnName = 'Adrian',
    NumericColumnNames = Features,
    CategoricalColumnNames = None,
    TextColumnNames = None,
    WeightColumnName = None,
    Threads = -1,
    InputFrame = 'datatable')

# Get args list for algorithm and target type
ModelArgs = ml.ML0_Parameters(
    Algorithms = 'LightGBM', 
    TargetType = 'Classification', 
    TrainMethod = 'Train')

# Update iterations to run quickly
ModelArgs.get('LightGBM').get('AlgoArgs')['num_iterations'] = 50

# Initialize RetroFit
x = ml.RetroFit(ModelArgs, ModelData, DataFrames)

# Train Model
x.ML1_Single_Train(Algorithm = 'LightGBM')

# Score data
x.ML1_Single_Score(
    DataName = x.DataSetsNames[2],
    ModelName = x.ModelListNames[0],
    Algorithm = 'LightGBM')

# Evaluate scored data
metrics = x.ML1_Single_Evaluate(
    FitName=x.FitListNames[0],
    TargetType=x.ModelArgs.get('LightGBM')['TargetType'],
    ScoredDataName=x.DataSetsNames[-1],
    ByVariables=None,
    CostDict=dict(tpcost=0, fpcost=1, fncost=1, tncost=0))

# Metrics
metrics.keys()

# Scoring data names
x.DataSetsNames

# Scoring data
x.DataSets.get('Scored_test_data_LightGBM_1')

# Check ModelArgs Dict
x.PrintAlgoArgs(Algo = 'LightGBM')

# List of model names
x.ModelListNames

# List of model fitted names
x.FitListNames
```

</p>
</details>


<details><summary>MultiClass Training</summary>
<p>

```python
####################################
# LightGBM MultiClass
####################################

# Setup Environment
import pkg_resources
import timeit
import datatable as dt
import retrofit
from retrofit import DatatableFE as dtfe
from retrofit import MachineLearning as ml

# Load some data
FilePath = pkg_resources.resource_filename('retrofit', 'datasets/MultiClassData.csv') 
data = dt.fread(FilePath)

# Instantiate Feature Engineering Class
FE = dtfe.FE()

# Dummify
data = FE.FE1_DummyVariables(
    data = data, 
    CategoricalColumnNames = ['Factor_2','Factor_3'],
    use_saved_args=False)
data = data[:, [name not in ['Factor_2','Factor_3'] for name in data.names]]

# Create Calendar Vars
data = FE.FE1_AutoCalendarVariables(
    data,
    DateColumnNames='DateTime',
    CalendarVariables=['wday','month','quarter'],
    use_saved_args=False)

# Type conversions for modeling
data = FE.FE2_ColTypeConversions(
    data,
    Int2Float=True,
    Bool2Float=True,
    RemoveDateCols=True,
    RemoveStrCols=False,
    SkipCols=None,
    use_saved_args=False)

# Drop Text Cols (no word2vec yet)
data = data[:, [z for z in data.names if z not in ['Comment']]]

# Create partitioned data sets
DataFrames = FE.FE2_AutoDataPartition(
    data, 
    DateColumnName = None, 
    PartitionType = 'random', 
    Ratios = [0.7,0.2,0.1], 
    ByVariables = None, 
    Sort = False,
    use_saved_args = False)

# Features
Features = [z for z in list(data.names) if not z in ['Adrian','DateTime','Comment','Weights']]

# Prepare modeling data sets
ModelData = ml.ML0_GetModelData(
    Processing = 'lightgbm',
    TrainData = DataFrames['TrainData'],
    ValidationData = DataFrames['ValidationData'],
    TestData = DataFrames['TestData'],
    ArgsList = None,
    TargetColumnName = 'Adrian',
    NumericColumnNames = Features,
    CategoricalColumnNames = None,
    TextColumnNames = None,
    WeightColumnName = None,
    Threads = -1,
    InputFrame = 'datatable')

# Get args list for algorithm and target type
ModelArgs = ml.ML0_Parameters(
    Algorithms = 'LightGBM', 
    TargetType = 'MultiClass', 
    TrainMethod = 'Train')

# Update iterations to run quickly
ModelArgs.get('LightGBM').get('AlgoArgs')['num_iterations'] = 50

# Initialize RetroFit
x = ml.RetroFit(ModelArgs, ModelData, DataFrames)

# Train Model
x.ML1_Single_Train(Algorithm = 'LightGBM')

# Score data
x.ML1_Single_Score(
    DataName = x.DataSetsNames[2],
    ModelName = x.ModelListNames[0],
    Algorithm = 'LightGBM')

# Evaluate scored data
metrics = x.ML1_Single_Evaluate(
    FitName=x.FitListNames[0],
    TargetType=x.ModelArgs.get('LightGBM')['TargetType'],
    ScoredDataName=x.DataSetsNames[-1],
    ByVariables=None,
    CostDict=dict(tpcost=0, fpcost=1, fncost=1, tncost=0))

# Metrics
metrics.keys()

# Scoring data names
x.DataSetsNames

# Scoring data
x.DataSets.get('Scored_test_data_LightGBM_1')

# Check ModelArgs Dict
x.PrintAlgoArgs(Algo = 'LightGBM')

# List of model names
x.ModelListNames

# List of model fitted names
x.FitListNames
```

</p>
</details>

</p>
</details>




</p>
</details>


</p>
</details>


## **Visualization**
<p>

<details><summary>Expand to view content</summary>
<p>

Code here

</p>
</details>
